{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://www.dataquest.io/blog/web-scraping-tutorial-python/\n",
    "def get_titles(weblink):\n",
    "    page = requests.get(weblink)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    title_items = soup.select('h4.artifact-title a')\n",
    "    title_names = [i.get_text() for i in title_items]\n",
    "    return title_names\n",
    "\n",
    "p1titles = get_titles(\"https://digital.lib.washington.edu/researchworks/handle/1773/20063/browse?rpp=20&sort_by=2&type=dateissued&offset=0&etal=-1&order=ASC\")\n",
    "p2titles = get_titles(\"https://digital.lib.washington.edu/researchworks/handle/1773/20063/browse?rpp=20&sort_by=2&type=dateissued&offset=20&etal=-1&order=ASC\")\n",
    "\n",
    "web_titles = p1titles + p2titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_alpha_titles(titleslist):\n",
    "    alpha_t = []\n",
    "    for i in titleslist:\n",
    "        strlist = re.findall(r\"[\\w']+\", i)\n",
    "        strwt = ' '.join(strlist)\n",
    "        alpha_t.append(strwt)\n",
    "    return alpha_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_csv_titles(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        # create empty array to hold each entry as a dict\n",
    "        data = []\n",
    "        # create a csv-reader object\n",
    "        reader = csv.DictReader(file)\n",
    "        # loop through each row in the csv-reader object...\n",
    "        for row in reader:\n",
    "            data.append(row['title'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_titles = load_csv_titles('./data/m.csv')\n",
    "# print(csv_titles)\n",
    "alpha_wt = get_alpha_titles(web_titles)\n",
    "alpha_ct = get_alpha_titles(csv_titles)\n",
    "\n",
    "missing_titles = [i for i in alpha_wt if i not in alpha_ct]\n",
    "missing_titles2 = [i for i in web_titles if i not in csv_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Murray', 'Star'],\n",
       " ['Hillius', 'William'],\n",
       " ['Driscoll', 'Jennifer'],\n",
       " ['Dvorak', 'Jessica'],\n",
       " ['Diak', 'Nicholas'],\n",
       " ['Mearns', 'Ian'],\n",
       " ['Williams', 'Jacob'],\n",
       " ['Murphy', 'Ruan'],\n",
       " ['LaFontaine', 'Michele'],\n",
       " ['Foley', 'Timothy'],\n",
       " ['Rybolt', 'Brian'],\n",
       " ['Anderson', 'Cynthia'],\n",
       " ['Campbell', 'Crystal'],\n",
       " ['Pierson', 'Marcie'],\n",
       " ['Laakso', 'Alysen'],\n",
       " ['McConnell', 'Jennifer'],\n",
       " ['Panzer', 'Sean'],\n",
       " ['Olive', 'Victoria'],\n",
       " ['Burns', 'John'],\n",
       " ['Kennedy', 'Kari'],\n",
       " ['Miller', 'Marc'],\n",
       " ['Montange', 'Leah'],\n",
       " ['Benjamin', 'Peter'],\n",
       " ['Mizic', 'Jessie'],\n",
       " ['Sanchez', 'Michelle'],\n",
       " ['Spruel', 'Rick'],\n",
       " ['Mseitif', 'Jesse'],\n",
       " ['Mseitif', 'Jesse'],\n",
       " ['Allen', 'Emily'],\n",
       " ['Spruel', 'Rick'],\n",
       " ['Jenkins', 'Artis'],\n",
       " ['Grove', 'Jonathan'],\n",
       " ['Avella', 'Douglas'],\n",
       " ['Fern', 'Anna'],\n",
       " ['Chapman', 'Kyle'],\n",
       " ['Douglas', 'Miguel'],\n",
       " ['Demmings', 'Naomi']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_authors(weblink):\n",
    "    page = requests.get(weblink)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    au_items = soup.select('div.artifact-info')\n",
    "    au_text = [i.get_text() for i in au_items]\n",
    "    alphanum_au = get_alpha_titles(au_text)\n",
    "    aulist_list = [re.findall('[%A-Za-z]+', i) for i in alphanum_au]\n",
    "    authors = [[i[0],i[1]] for i in aulist_list]\n",
    "    return authors\n",
    "\n",
    "p1au = get_authors(\"https://digital.lib.washington.edu/researchworks/handle/1773/20063/browse?rpp=20&sort_by=2&type=dateissued&offset=0&etal=-1&order=ASC\")\n",
    "p2au = get_authors(\"https://digital.lib.washington.edu/researchworks/handle/1773/20063/browse?rpp=20&sort_by=2&type=dateissued&offset=20&etal=-1&order=ASC\")\n",
    "web_aus = p1au + p2au\n",
    "web_aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pierson', 'Marcie'],\n",
       " ['Campbell', 'Crystal'],\n",
       " ['Anderson', 'Cynthia'],\n",
       " ['Rybolt', 'Brian'],\n",
       " ['Foley', 'Timothy'],\n",
       " ['Murphy', 'Ruan'],\n",
       " ['LaFontaine', 'Michele'],\n",
       " ['Hillius', 'William'],\n",
       " ['Dvorak', 'Jessica'],\n",
       " ['Driscoll', 'Jennifer'],\n",
       " ['Murray', 'Star'],\n",
       " ['Mearns', 'Ian'],\n",
       " ['Diak', 'Nicholas'],\n",
       " ['Zeller', 'Theresa'],\n",
       " ['Coney', 'Cheryl'],\n",
       " ['Rangel', 'Cesar'],\n",
       " ['Pryor', 'Lindsay'],\n",
       " ['LaFountain', 'Tamara'],\n",
       " ['Hughes', 'Christina'],\n",
       " ['Benge', 'Lizbett'],\n",
       " ['Morgan', 'Sonja'],\n",
       " ['Howard', 'Jacinda'],\n",
       " ['Lundberg', 'Margaret'],\n",
       " ['Panzer', 'Sean'],\n",
       " ['Spruel', 'Rick'],\n",
       " ['Mseitif', 'Jesse'],\n",
       " ['Avella', 'Douglas'],\n",
       " ['Grove', 'Jonathan'],\n",
       " ['Hicks', 'Thomas'],\n",
       " ['Stewart', 'Kayla'],\n",
       " ['Allen', 'Emily'],\n",
       " ['Jenkins', 'Artis'],\n",
       " ['Montange', 'Leah'],\n",
       " ['Sanchez', 'Michelle'],\n",
       " ['Kari', 'Kennedy'],\n",
       " ['Mizic', 'Jessie'],\n",
       " ['Benjamin', 'Peter'],\n",
       " ['Miller', 'Marc'],\n",
       " ['Burns', 'John'],\n",
       " ['Hardin', 'Patrick'],\n",
       " ['Smith', 'Daniel'],\n",
       " ['Hill', 'Victoria'],\n",
       " ['Fern', 'Anna'],\n",
       " ['Amili', 'Frelimo'],\n",
       " ['.', '.'],\n",
       " ['Douglas', 'Miguel']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_csv_aus(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        # create empty array to hold each entry as a dict\n",
    "        data = []\n",
    "        # create a csv-reader object\n",
    "        reader = csv.DictReader(file)\n",
    "        # loop through each row in the csv-reader object...\n",
    "        for row in reader:\n",
    "            author = [row['author1_lname'],row['author1_fname']]\n",
    "            data.append(author)\n",
    "    return data\n",
    "csv_aus = load_csv_aus('./data/m.csv')\n",
    "csv_aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Campbell', 'Crystal'] in csv_aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Williams', 'Jacob'], ['Laakso', 'Alysen'], ['McConnell', 'Jennifer'], ['Olive', 'Victoria'], ['Kennedy', 'Kari'], ['Chapman', 'Kyle'], ['Demmings', 'Naomi']]\n",
      "7\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "missing_au = [i for i in web_aus if i not in csv_aus]\n",
    "print(missing_au)\n",
    "print(len(missing_au))\n",
    "print(len(missing_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_web_info(weblink):\n",
    "    page = requests.get(weblink)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    title_items = soup.select('h4.artifact-title a')\n",
    "    title_names = [i.get_text() for i in title_items]\n",
    "    alpha_titles = get_alpha_titles(title_names)\n",
    "\n",
    "    link_items = soup.select('h4.artifact-title a[href]')\n",
    "    link_text = [i['href'] for i in link_items]\n",
    "    full_link_text = ['https://digital.lib.washington.edu'+i+'?show=full' for i in link_text]\n",
    "\n",
    "    au_items = soup.select('div.artifact-info')\n",
    "    au_text = [i.get_text() for i in au_items]\n",
    "    alphanum_au = get_alpha_titles(au_text)\n",
    "    aulist_list = [re.findall('[%A-Za-z]+', i) for i in alphanum_au]\n",
    "    authors = [[i[0],i[1]] for i in aulist_list]\n",
    "\n",
    "    keys = ['alphatitle','title','link','author','sm_auth']\n",
    "    values = list(zip(alpha_titles,title_names,full_link_text,aulist_list,authors))\n",
    "    web_info = [dict(zip(keys, v)) for v in values]\n",
    "    return web_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1 = get_web_info(\"https://digital.lib.washington.edu/researchworks/handle/1773/20063/browse?rpp=20&sort_by=2&type=dateissued&offset=0&etal=-1&order=ASC\")\n",
    "p2 = get_web_info(\"https://digital.lib.washington.edu/researchworks/handle/1773/20063/browse?rpp=20&sort_by=2&type=dateissued&offset=20&etal=-1&order=ASC\")\n",
    "web_info = p1 + p2\n",
    "# print(web_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_info = [i for i in web_info if i['alphatitle'] in missing_titles]\n",
    "missing_info2 = [i for i in web_info if i['sm_auth'] in missing_au]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alphatitle': \"Modernizing the Greek Tragedy Clint Eastwood's Impact on the Western\",\n",
       "  'author': ['Williams', 'Jacob', 'A'],\n",
       "  'link': 'https://digital.lib.washington.edu/researchworks/handle/1773/20881?show=full',\n",
       "  'sm_auth': ['Williams', 'Jacob'],\n",
       "  'title': \"Modernizing the Greek Tragedy: Clint Eastwood's Impact on the Western\"},\n",
       " {'alphatitle': 'Building Sustainable Behavior through Social Marketing Encouraging Reusable Shopping Bag Use at Stadium Thriftway in Tacoma WA A Case Study',\n",
       "  'author': ['Laakso', 'Alysen', 'Kristen'],\n",
       "  'link': 'https://digital.lib.washington.edu/researchworks/handle/1773/24105?show=full',\n",
       "  'sm_auth': ['Laakso', 'Alysen'],\n",
       "  'title': 'Building Sustainable Behavior through Social Marketing: Encouraging Reusable Shopping Bag Use at Stadium Thriftway in Tacoma, WA - A Case Study'},\n",
       " {'alphatitle': 'David and Goliath Individualism and Liberty in the Italian Renaissance and the American Revolution',\n",
       "  'author': ['McConnell', 'Jennifer'],\n",
       "  'link': 'https://digital.lib.washington.edu/researchworks/handle/1773/24106?show=full',\n",
       "  'sm_auth': ['McConnell', 'Jennifer'],\n",
       "  'title': 'David and Goliath: Individualism and Liberty in the Italian Renaissance and the American Revolution'},\n",
       " {'alphatitle': 'Sexual Violence in a Native American Community Native American Women Speak Out',\n",
       "  'author': ['Olive', 'Victoria', 'Catherine'],\n",
       "  'link': 'https://digital.lib.washington.edu/researchworks/handle/1773/35108?show=full',\n",
       "  'sm_auth': ['Olive', 'Victoria'],\n",
       "  'title': 'Sexual Violence in a Native American Community: Native American Women Speak Out'},\n",
       " {'alphatitle': 'Navigating the American Healthcare System as an Obese Person Developing Effective Community Based Treatment Strategies for Healthcare Providers',\n",
       "  'author': ['Kennedy', 'Kari', 'G'],\n",
       "  'link': 'https://digital.lib.washington.edu/researchworks/handle/1773/33515?show=full',\n",
       "  'sm_auth': ['Kennedy', 'Kari'],\n",
       "  'title': 'Navigating the American Healthcare System as an Obese Person: Developing Effective Community-Based Treatment Strategies for Healthcare Providers'},\n",
       " {'alphatitle': 'Digital Activism How Social Media Prevalence has Impacted Modern Activism',\n",
       "  'author': ['Chapman', 'Kyle', 'Joseph'],\n",
       "  'link': 'https://digital.lib.washington.edu/researchworks/handle/1773/36431?show=full',\n",
       "  'sm_auth': ['Chapman', 'Kyle'],\n",
       "  'title': 'Digital Activism: How Social Media Prevalence has Impacted Modern Activism'},\n",
       " {'alphatitle': 'HIVAIDS Social Stigma and Visual Art',\n",
       "  'author': ['Demmings', 'Naomi'],\n",
       "  'link': 'https://digital.lib.washington.edu/researchworks/handle/1773/38049?show=full',\n",
       "  'sm_auth': ['Demmings', 'Naomi'],\n",
       "  'title': 'HIVAIDS Social Stigma and Visual Art'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_info2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dc.contributor.advisor': ['Jolly, Natalie', 'Chamberlain, Ed'],\n",
       " 'dc.contributor.author': 'Demmings, Naomi',\n",
       " 'dc.date.accessioned': '2017-02-14T22:35:34Z',\n",
       " 'dc.date.submitted': '2016-12',\n",
       " 'dc.description': \"Thesis (Master's)--University of Washington, 2016-12\",\n",
       " 'dc.description.abstract': 'The purpose of this research is to examine the development and progression of HIV/AIDS stigma within a social structure of power and powerlessness from the early 1980s to the 2010s, through a case study of selected visual images. I focus on the social aspect of how HIV/AIDS is given social stigmas that cause as much suffering as the disease’s physical health effects.  To do this, I apply Erving Goffman’s theory on stigma and analyzing visual images from the early 1980s, 1990s and early 2000s to consider how HIV/AIDS has been constructed and reinforced through time. In considering the historical context I show that each of these images responds to stigma as it existed in the early 1980s but also in the ways that it exists today.',\n",
       " 'dc.embargo.lift': '2018-02-14T22:35:34Z',\n",
       " 'dc.embargo.terms': 'Delay release for 1 year -- then make Open Access',\n",
       " 'dc.format.mimetype': 'application/pdf',\n",
       " 'dc.identifier.other': 'Demmings_washington_0250O_16652.pdf',\n",
       " 'dc.identifier.uri': 'http://hdl.handle.net/1773/38049',\n",
       " 'dc.language.iso': 'en_US',\n",
       " 'dc.rights': 'CC BY-NC-ND',\n",
       " 'dc.subject': ['HIV/AIDS', 'Stigma', 'Visual Art'],\n",
       " 'dc.subject.other': ['Art criticism',\n",
       "  'Art history',\n",
       "  'Sociology',\n",
       "  'interdisciplinary arts and sciences - tacoma'],\n",
       " 'dc.title': 'HIVAIDS Social Stigma and Visual Art',\n",
       " 'dc.type': 'Thesis'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dc_info(weblink):\n",
    "    page = requests.get(weblink)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find(\"table\", attrs={\"class\":\"ds-includeSet-table detailtable table table-striped table-hover\"})\n",
    "    #table_rows = table.find_all(\"tr\")\n",
    "    table_heads = [h.get_text() for h in table.find_all(\"td\", attrs={'class':'label-cell'})]\n",
    "    table_info = [i.get_text() for i in table.find_all(\"td\", attrs={'class':'word-break'})]\n",
    "    # if do dict zip, removes duplicate keys! so get a list of tuple\n",
    "    all_heads_info = list(zip(table_heads,table_info))\n",
    "    # then create a new dict where each value is a list\n",
    "    dict_heads_info = {}\n",
    "    for x, y in all_heads_info:\n",
    "        dict_heads_info.setdefault(x, []).append(y)\n",
    "    # then, flatten 1 item lists\n",
    "    for k,v in dict_heads_info.items():\n",
    "        if len(v) == 1:\n",
    "            dict_heads_info[k] = v[0]\n",
    "            #print(v)\n",
    "    return dict_heads_info\n",
    "get_dc_info('https://digital.lib.washington.edu/researchworks/handle/1773/38049?show=full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_ex_data(missing_info):\n",
    "    spreadsheet = []\n",
    "    for row in missing_info:\n",
    "        full_info = get_dc_info(row['link'])\n",
    "        ex_row = {}\n",
    "\n",
    "        ex_row['title'] = row['title']\n",
    "        ex_row['author1_fname'] = row['author'][1]\n",
    "        if len(row['author']) == 3:\n",
    "            ex_row['author1_mname'] = row['author'][2]\n",
    "        else:\n",
    "            ex_row['author1_mname'] = ''\n",
    "        ex_row['author1_lname'] = row['author'][0]\n",
    "        ex_row['author1_institution'] = 'University of Washington Tacoma'\n",
    "        ex_row['author1_email'] = ''\n",
    "        ex_row['fulltext_url'] = full_info['dc.identifier.uri']\n",
    "        ex_row['author1_suffix'] = ''\n",
    "        ex_row['season'] = ''\n",
    "        ex_row['comments'] = ''\n",
    "        ex_row['degree_name'] = 'Master of Arts in Interdisciplinary Studies (MAIS)'\n",
    "        ex_row['abstract'] = full_info['dc.description.abstract']\n",
    "        ex_row['publication_date'] = full_info['dc.date.accessioned']\n",
    "        ex_row['department'] = 'Interdisciplinary Arts and Sciences'\n",
    "\n",
    "        if '1 year' in full_info['dc.embargo.terms']:\n",
    "            ex_row['document_type'] = 'restrict_1yr'\n",
    "        elif '2 years' in full_info['dc.embargo.terms']:\n",
    "            ex_row['document_type'] = 'restrict_2yr'\n",
    "        elif '5 years' in full_info['dc.embargo.terms']:\n",
    "            ex_row['document_type'] = 'restrict_5yr'\n",
    "        else:\n",
    "            ex_row['document_type'] = 'open_access'\n",
    "\n",
    "        if 'dc.embargo.lift' in full_info:\n",
    "            ex_row['date_avail'] = full_info['dc.embargo.lift']\n",
    "        else:\n",
    "            ex_row['date_avail'] = ''\n",
    "\n",
    "        if isinstance(full_info['dc.contributor.advisor'], str):\n",
    "            #for name in full_info['dc.contributor.advisor']:\n",
    "            namelist = full_info['dc.contributor.advisor'].split(', ')\n",
    "            ex_row['advisor1'] = namelist[1]+' '+namelist[0]\n",
    "            ex_row['advisor2'] = ''\n",
    "            ex_row['advisor3'] = ''\n",
    "            ex_row['advisor4'] = ''\n",
    "        elif len(full_info['dc.contributor.advisor']) == 2:\n",
    "            names = full_info['dc.contributor.advisor']\n",
    "            namelist1 = names[0].split(', ')\n",
    "            #print(full_info['dc.contributor.advisor'])\n",
    "            ex_row['advisor1'] = namelist1[1]+' '+namelist1[0]\n",
    "            namelist2 = names[1].split(', ')\n",
    "            ex_row['advisor2'] = namelist2[1]+' '+namelist2[0]\n",
    "            ex_row['advisor3'] = ''\n",
    "            ex_row['advisor4'] = ''\n",
    "        elif len(full_info['dc.contributor.advisor']) == 3:\n",
    "            names = full_info['dc.contributor.advisor']\n",
    "            namelist1 = names[0].split(', ')\n",
    "            ex_row['advisor1'] = namelist1[1]+' '+namelist1[0]\n",
    "            namelist2 = names[1].split(', ')\n",
    "            ex_row['advisor2'] = namelist2[1]+' '+namelist2[0]\n",
    "            namelist3 = names[2].split(', ')\n",
    "            ex_row['advisor3'] = namelist3[1]+' '+namelist3[0]\n",
    "            ex_row['advisor4'] = ''\n",
    "        elif len(full_info['dc.contributor.advisor']) == 4:\n",
    "            names = full_info['dc.contributor.advisor']\n",
    "            namelist1 = names[0].split(', ')\n",
    "            ex_row['advisor1'] = namelist1[1]+' '+namelist1[0]\n",
    "            namelist2 = names[1].split(', ')\n",
    "            ex_row['advisor2'] = namelist2[1]+' '+namelist2[0]\n",
    "            namelist3 = names[2].split(', ')\n",
    "            ex_row['advisor3'] = namelist3[1]+' '+namelist3[0]\n",
    "            namelist4 = names[3].split(', ')\n",
    "            ex_row['advisor4'] = namelist4[1]+' '+namelist4[0]\n",
    "\n",
    "        if full_info['dc.type'] == 'Thesis':\n",
    "            ex_row['work_type'] = 'Masters Thesis'\n",
    "        else:\n",
    "            ex_row['work_type'] = 'Masters Capstone Project'\n",
    "\n",
    "        if isinstance(full_info['dc.subject'], str):\n",
    "            ex_row['keywords'] = full_info['dc.subject'].replace(';',',')\n",
    "            #print(ex_row['keywords'])\n",
    "        else:\n",
    "            #print(full_info['dc.subject'].type())\n",
    "            ex_row['keywords'] = ', '.join(full_info['dc.subject'])\n",
    "\n",
    "\n",
    "        if 'interdisciplinary arts and sciences - tacoma' in full_info['dc.subject.other']:\n",
    "            full_info['dc.subject.other'].remove('interdisciplinary arts and sciences - tacoma')\n",
    "            ex_row['disciplines'] = '; '.join(full_info['dc.subject.other'])\n",
    "        elif 'Interdisciplinary arts and sciences - Tacoma' in full_info['dc.subject.other']:\n",
    "            full_info['dc.subject.other'].remove('Interdisciplinary arts and sciences - Tacoma')\n",
    "            ex_row['disciplines'] = '; '.join(full_info['dc.subject.other'])\n",
    "        else:\n",
    "            ex_row['disciplines'] = '; '.join(full_info['dc.subject.other'])\n",
    "\n",
    "        spreadsheet.append(ex_row)\n",
    "    return spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spreadsheet = create_ex_data(missing_info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write(data, output):\n",
    "    fieldnames = ['title', 'publication_date', 'season', 'document_type', 'date_avail', \n",
    "              'work_type', 'degree_name', 'department', 'advisor1', 'advisor2',\n",
    "              'advisor3', 'advisor4', 'keywords', 'disciplines', 'abstract', \n",
    "              'comments', 'fulltext_url', 'author1_fname', 'author1_mname', 'author1_lname', \n",
    "              'author1_suffix', 'author1_email', 'author1_institution']\n",
    "    with open(output, 'w', newline='',encoding='utf-8-sig') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data)\n",
    "\n",
    "write(spreadsheet, './data/mais_update.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
